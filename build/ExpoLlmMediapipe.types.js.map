{"version":3,"file":"ExpoLlmMediapipe.types.js","sourceRoot":"","sources":["../src/ExpoLlmMediapipe.types.ts"],"names":[],"mappings":"","sourcesContent":["export type OnLoadEventPayload = {\n  url: string;\n};\n\nexport type ExpoLlmMediapipeModuleEvents = {\n  onChange: (params: ChangeEventPayload) => void;\n  onPartialResponse: (params: PartialResponseEventPayload) => void;\n  onErrorResponse: (params: ErrorResponseEventPayload) => void;\n  logging: (params: LoggingEventPayload) => void;\n  downloadProgress: (params: DownloadProgressEvent) => void;\n};\n\nexport type ChangeEventPayload = {\n  value: string;\n};\n\nexport type PartialResponseEventPayload = {\n  handle: number;\n  requestId: number;\n  response: string;\n};\n\nexport type ErrorResponseEventPayload = {\n  handle: number;\n  requestId: number;\n  error: string;\n};\n\nexport type LoggingEventPayload = {\n  handle: number;\n  message: string;\n};\n\nexport type MediaAttachment = {\n  type: \"image\" | \"audio\";\n  uri: string;\n};\n\nexport type GenerationInput = {\n  prompt: string;\n  attachments?: MediaAttachment[];\n};\n\nexport type PromptOrInput = string | GenerationInput;\n\n// LLM Types and Hook\ntype LlmModelLocation =\n  | { storageType: \"asset\"; modelName: string }\n  | { storageType: \"file\"; modelPath: string };\n\nexport type LlmInferenceConfig = LlmModelLocation & {\n  maxTokens?: number;\n  topK?: number;\n  temperature?: number;\n  randomSeed?: number;\n};\n\nexport interface DownloadProgressEvent {\n  modelName: string;\n  url?: string;\n  bytesDownloaded?: number;\n  totalBytes?: number;\n  progress?: number;\n  status: \"downloading\" | \"completed\" | \"error\" | \"cancelled\";\n  error?: string;\n}\n\nexport interface DownloadOptions {\n  overwrite?: boolean;\n  timeout?: number;\n  headers?: Record<string, string>;\n}\n\ntype BaseLlmParams = {\n  maxTokens?: number;\n  topK?: number;\n  temperature?: number;\n  randomSeed?: number;\n};\n\n/**\n * Props for the `useLLM` hook.\n * - If `modelUrl` is provided, `modelName` is also required for downloadable models.\n * - Otherwise, `storageType` and either `modelName` (for assets) or `modelPath` (for files) are required.\n */\n// This existing UseLLMProps is a good union type for the implementation signature.\nexport type UseLLMProps = BaseLlmParams & (\n  | { modelUrl?: undefined; storageType: \"asset\"; modelName: string; modelPath?: undefined }\n  | { modelUrl?: undefined; storageType: \"file\"; modelPath: string; modelName?: undefined }\n  | { modelUrl: string; modelName: string; storageType?: undefined; modelPath?: undefined }\n);\n\n// Specific prop types for hook overloads\nexport type UseLLMAssetProps = BaseLlmParams & { modelUrl?: undefined; storageType: \"asset\"; modelName: string; modelPath?: undefined };\nexport type UseLLMFileProps = BaseLlmParams & { modelUrl?: undefined; storageType: \"file\"; modelPath: string; modelName?: undefined };\nexport type UseLLMDownloadableProps = BaseLlmParams & { modelUrl: string; modelName: string; storageType?: undefined; modelPath?: undefined };\n\n\n// Return types for the useLLM hook\nexport interface BaseLlmReturn {\n  generateResponse: (\n    input: PromptOrInput,\n    onPartial?: (partial: string, reqId: number | undefined) => void,\n    onErrorCb?: (message: string, reqId: number | undefined) => void,\n    abortSignal?: AbortSignal\n  ) => Promise<string>;\n  generateStreamingResponse: (\n    input: PromptOrInput,\n    onPartial?: (partial: string, reqId: number) => void,\n    onErrorCb?: (message: string, reqId: number) => void,\n    abortSignal?: AbortSignal\n  ) => Promise<void>;\n  isLoaded: boolean;\n}\n\nexport interface DownloadableLlmReturn extends BaseLlmReturn {\n  downloadModel: (options?: DownloadOptions) => Promise<boolean>;\n  loadModel: () => Promise<void>;\n  downloadStatus: \"not_downloaded\" | \"downloading\" | \"downloaded\" | \"error\";\n  downloadProgress: number;\n  downloadError: string | null;\n  isCheckingStatus: boolean;\n}\n\nexport interface NativeModuleSubscription {\n  remove(): void;\n}\n\nexport interface ExpoLlmMediapipeModule {\n  /**\n   * Creates a model from a file path.\n   * @param modelPath - The path to the model file.\n   * @param maxTokens - The maximum number of tokens to generate.\n   * @param topK - The number of top tokens to consider.\n   * @param temperature - The temperature for sampling.\n   * @param randomSeed - The random seed for reproducibility.\n   * @returns A promise that resolves to the model handle.\n   */\n  createModel(\n    modelPath: string,\n    maxTokens: number,\n    topK: number,\n    temperature: number,\n    randomSeed: number,\n  ): Promise<number>;\n\n  /**\n   * Creates a model from an asset.\n   * @param modelName - The name of the model asset.\n   * @param maxTokens - The maximum number of tokens to generate.\n   * @param topK - The number of top tokens to consider.\n   * @param temperature - The temperature for sampling.\n   * @param randomSeed - The random seed for reproducibility.\n   * @returns A promise that resolves to the model handle.\n   */\n  createModelFromAsset(\n    modelName: string,\n    maxTokens: number,\n    topK: number,\n    temperature: number,\n    randomSeed: number,\n  ): Promise<number>;\n  releaseModel(handle: number): Promise<boolean>;\n\n  /**\n   * Generates a response based on the provided prompt.\n   * @param handle - The model handle.\n   * @param requestId - The unique request identifier.\n   * @param prompt - The input prompt for the model.\n   * @returns A promise that resolves to the generated response.\n   */\n  generateResponse(\n    handle: number,\n    requestId: number,\n    prompt: string,\n    imageUris?: string[],\n  ): Promise<string>;\n\n  /**\n   * Generates a response asynchronously based on the provided prompt.\n   * @param handle - The model handle.\n   * @param requestId - The unique request identifier.\n   * @param prompt - The input prompt for the model.\n   * @returns A promise that resolves to a boolean indicating success or failure.\n   */\n  generateResponseAsync(\n    handle: number,\n    requestId: number,\n    prompt: string,\n    imageUris?: string[],\n  ): Promise<boolean>;\n\n  /**\n   * Checks if a model is downloaded.\n   * @param modelName - The name of the model to check.\n   * @returns A promise that resolves to a boolean indicating if the model is downloaded.\n   */\n  isModelDownloaded(modelName: string): Promise<boolean>;\n\n  /**\n   * Lists all downloaded models.\n   * @returns A promise that resolves to an array of model names.\n   */\n  getDownloadedModels(): Promise<string[]>;\n\n  /**\n   * Deletes a downloaded model.\n   * @param modelName - The name of the model to delete.\n   * @returns A promise that resolves to a boolean indicating success or failure.\n   */\n  deleteDownloadedModel(modelName: string): Promise<boolean>;\n\n  /**\n   * Downloads a model from a given URL.\n   * @param url - The URL to download the model from.\n   * @param modelName - The name to save the downloaded model as.\n   * @param options - Optional download options.\n   * @returns A promise that resolves to a boolean indicating success or failure.\n   */\n  downloadModel(\n    url: string,\n    modelName: string,\n    options?: DownloadOptions,\n  ): Promise<boolean>;\n\n  /**\n   * Cancels a model download.\n   * @param modelName - The name of the model to cancel the download for.\n   * @returns A promise that resolves to a boolean indicating success or failure.\n   */\n  cancelDownload(modelName: string): Promise<boolean>;\n\n  /**\n   * Creates a model from a downloaded file.\n   * @param modelName - The name of the downloaded model.\n   * @param maxTokens - The maximum number of tokens to generate.\n   * @param topK - The number of top tokens to consider.\n   * @param temperature - The temperature for sampling.\n   * @param randomSeed - The random seed for reproducibility.\n   * @returns A promise that resolves to the model handle.\n   */\n  createModelFromDownloaded(\n    modelName: string,\n    maxTokens?: number,\n    topK?: number,\n    temperature?: number,\n    randomSeed?: number,\n  ): Promise<number>;\n\n  /**\n   * Adds a listener for a specific event.\n   * @param eventName - The name of the event to listen for.\n   * @param listener - The callback function to execute when the event occurs.\n   * @returns A subscription object to manage the listener.\n   */\n  addListener<EventName extends keyof ExpoLlmMediapipeModuleEvents>(\n    eventName: EventName,\n    listener: ExpoLlmMediapipeModuleEvents[EventName],\n  ): NativeModuleSubscription;\n\n  /**\n   * Removes all listeners for a specific event.\n   * @param event - The name of the event to remove listeners for.\n   * @returns A promise that resolves when all listeners have been removed.\n   */\n  removeAllListeners(event: keyof ExpoLlmMediapipeModuleEvents): void;\n}\n"]}